# Project Plan: ArduPilot AI Log Diagnosis (GSoC 2026)

## 1. Overview
An AI-assisted log diagnosis tool for ArduPilot `.BIN` dataflash logs. Extended from a rule-based prototype into a full **hybrid rule + XGBoost** engine over the 12-week GSoC period. Parses logs, extracts 60+ numerical features, identifies the **root cause** of flight failures (not just symptoms), and outputs actionable maintainer reports.

**Status as of 2026-02-28**: P0, P1, P2, P3 complete. P4 in progress. Production sign-off granted.

## 2. Project Type
**BACKEND** â€” Data Processing, CLI Tool, ML Pipeline

## 3. Success Criteria

| Criterion | Target | Status |
|---|---|---|
| Parse `.BIN` files in < 2â€“3 seconds | < 2s | âœ… Done |
| Extract 60+ features (handles missing messages) | 60+ | âœ… Done |
| Hybrid Diagnosis Engine (Rules + XGBoost) < 100ms | < 100ms | âœ… Done |
| Cosine similarity retrieval for similar cases | Top-3 matches | âœ… Done |
| Structured JSON + human-readable terminal reports | Both formats | âœ… Done |
| Comprehensive test suite (unit + integration) | 56 tests passing | âœ… Done |
| Root-cause Top-1 > 50% on unseen holdout | > 50â€“60% | ğŸ”„ In Progress |
| ECE (Expected Calibration Error) â‰¤ 0.08 | â‰¤ 0.08 | ğŸ”„ Measuring |
| False Critical Rate â‰¤ 10% | â‰¤ 10% | ğŸ”„ In Progress |
| Triage-time reduction â‰¥ 40% | â‰¥ 40% | âœ… Done (242Ã— speedup) |

## 4. Tech Stack
- **Language**: Python 3.10+
- **Core Processing**: `pymavlink` (BIN parsing), `numpy`
- **Machine Learning**: `scikit-learn` (standard scaler, calibration), `xgboost` (multi-label classifier)
- **Data & Training**: `pandas`, `matplotlib`, `scipy` (FFT features)
- **Configuration**: `pyyaml`
- **Testing**: `pytest`
- **Linting**: `ruff`
- **CI**: GitHub Actions

## 5. File Structure (Implemented)
```
ardupilot-log-diagnosis/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ parser/         # pymavlink .BIN ingestion â€” COMPLETE
â”‚   â”œâ”€â”€ features/       # 60+ feature extractors â€” COMPLETE
â”‚   â”œâ”€â”€ diagnosis/      # Hybrid engine, rule engine, decision policy â€” COMPLETE
â”‚   â”œâ”€â”€ retrieval/      # Cosine-similarity case retrieval â€” COMPLETE
â”‚   â”œâ”€â”€ reporting/      # CLI + JSON report formatting â€” COMPLETE
â”‚   â””â”€â”€ cli/            # Entry point â€” COMPLETE
â”œâ”€â”€ models/             # Versioned artifacts (classifier, scaler, schemas)
â”œâ”€â”€ training/           # Dataset build, holdout, benchmark runner
â”œâ”€â”€ ops/                # Expert label mining pipeline
â”œâ”€â”€ tests/              # 56 passing tests
â””â”€â”€ docs/               # GSoC plan, triage study, acceptance criteria
```

## 6. Task Completion Board

| Task ID | Name | Priority | Status |
|---------|------|----------|--------|
| T1 | Scaffold Project Structure | P0 | âœ… Complete |
| T2 | Module 1: Log Parser | P0 | âœ… Complete |
| T3 | Module 2: Feature Pipeline Base (37+ features) | P1 | âœ… Complete |
| T4 | Module 2: Advanced Features (60+ total, FFT + EKF) | P1 | âœ… Complete |
| T5 | Module 3: Rule Engine v2 (all labels covered) | P1 | âœ… Complete |
| T6 | ML Pipeline & XGBoost Classifier | P1 | âœ… Complete |
| T7 | Module 3: Hybrid Fusion Engine | P2 | âœ… Complete |
| T8 | Module 4: Retrieval Engine (cosine similarity) | P2 | âœ… Complete |
| T9 | Module 5 & 6: Reporting + CLI | P2 | âœ… Complete |
| T10 | Testing & Documentation | P3 | âœ… Complete (56 tests) |
| T11 | Root-cause arbitration + cascade suppression | P3 | âœ… Complete |
| T12 | Maintainer triage study (P4-02) | P4 | âœ… Complete (242Ã— speedup) |
| T13 | False-critical audit + ECE calibration | P4 | ğŸ”„ In Progress |

## 7. Verification Status

- [x] **Linting**: `ruff` enforced.
- [x] **Unit Tests**: `pytest -q` â€” 56 passed, 0 failed.
- [x] **Integration Tests**: Full pipeline (`.BIN â†’ parsing â†’ hybrid diagnosis â†’ CLI output`).
- [x] **Schema Consistency**: Feature names consistent across `FeaturePipeline`, `FEATURE_NAMES`, and model artifacts.
- [x] **ML Cross-Validation**: Run on production training dataset.
- [x] **Leakage Check**: `validate_leakage.py` â€” 0 overlapping SHAs between train and holdout.
- [x] **Project Boundaries**: `training/validate_project_boundaries.py` â€” CI-enforced.
- [ ] **Final ECE report**: Target â‰¤ 0.08.
- [ ] **False-critical audit**: Target â‰¤ 10%.

## 8. Data Provenance and Curation
- Ground-truth labels audited and relabeled against the **Root-Cause Precedence policy** (`docs/root_cause_policy.md`).
- Holdout sets are SHA256-deduplicated against all training batches (`validate_leakage.py`).
- Clean import pipeline enforces: SHA dedup, non-log rejection, provenance proof, benchmark-ready export.
- Diagnosis benchmark data is strictly isolated from the companion-health application.
- Full curation audit trail: `training/validate_project_boundaries.py`.

## 9. GSoC Timeline

| Phase | Weeks | Milestone | Deliverables | Status |
|---|---|---|---|---|
| Community Bonding | CB1â€“CB3 | Diagnostics scope lock | Label taxonomy v1, benchmark protocol | âœ… Done |
| Coding Phase 1 | W1â€“W2 | Reliability foundation | Parser/feature contracts, 0 runtime crashes | âœ… Done |
| Coding Phase 1 | W3â€“W4 | Explainable Rule Engine v2 | Evidence + recommendation on every diagnosis | âœ… Done |
| Coding Phase 1 | W5â€“W6 | Hybrid v1 + calibration | Reproducible training pipeline, abstain logic | âœ… Done |
| Midterm | End W6 | Formal checkpoint | Stable CLI + reproducible benchmark demo | âœ… Done |
| Coding Phase 2 | W7â€“W8 | Causal timeline engine | Root-cause arbitration, cascade suppression | âœ… Done |
| Coding Phase 2 | W9â€“W10 | Actionable diagnostics | Top-problem + top-3-checks + ranked fixes | âœ… Done |
| Coding Phase 2 | W11 | Stress-reduction validation | Triage study: 242Ã— speedup documented | âœ… Done |
| Coding Phase 2 | W12 | Final release + handoff | Final docs, model card, benchmark report | ğŸ”„ In Progress |
| Final Evaluation | End W12 | Submission | GSoC final report + merged docs | â³ Upcoming |

## 10. Industry Standards Delivered

- **Causal diagnosis, not symptom spam**: identifies root cause first.
- **Confidence honesty**: calibrated probabilities + mandatory abstain/human-review state.
- **Evidence traceability**: every diagnosis tied to exact feature/value/threshold/timestamp.
- **Provenance-safe benchmarks**: no fabricated labels, no leakage, reproduced from clean state.
- **Maintainer KPI focus**: success measured by triage-time reduction, not just F1.
- **Reproducible science**: single-command benchmark reproduction, documented model behaviour.

# The Unbreakable Action Plan: Conquering the ML Phase

Based on the `PLAN-gsoc-architecture.md` and the recent data leakage discovery, we now possess the crucial insight needed to hit our production targets (>85% Top-1 Accuracy, >0.70 F1). 

The problem is no longer **code**, the problem is **label alignment**. High-level human labels ("Crash - Mechanical") do not match low-level telemetry data ("Vibration Spike at t=42s"). 

Here is the exact algorithmic plan to cross the final threshold.

---

## ðŸŸ© Phase 1: The Great Relabeling (Execution of the Root-Cause Precedence Policy)
**Reference:** GSoC Task T6 (ML Pipeline)
**The Problem:** Training XGBoost on human-derived symptomatic strings (e.g. `rc_failsafe` or `mechanical_failure`) forces the AI to memorize noise rather than math.
**The Fix:**
1. Execute a diagnostic pass across the 44-log master pool purely using the `RuleEngine`.
2. Inspect logs that throw `"mechanical_failure"` or `"crash_unknown"` but trigger massive internal rule alerts (like `vibe_z_max > 60` or `mag_field_range > 500`).
3. Overwrite the human label in `ground_truth.json` with the strongest underlying telemetry failure (e.g., change `mechanical_failure` to `vibration_high`).
*This instantly transforms "misclassifications" into True Positives for both the rules and ML models.*

## ðŸŸ© Phase 2: Fortifying the Temporal Arbiter
**Reference:** GSoC Task T7 (Hybrid Engine)
**The Problem:** Cascading failures (Vibration physically shakes the flight controller â†’ breaking the Magnetometer â†’ causing EKF fallback â†’ triggering a Failsafe).
**The Fix:**
1. Update `src/features/feature_extractor.py` to ensure `tanomaly` (Time of Anomaly) is flawlessly extracted for all 6 core failure modes.
2. The `HybridEngine` already includes the Temporal Arbiter, but it requires valid `tanomaly` timestamps to sort consequences. Once it accurately sorts by $T_{onset}$, precision naturally scales because "symptom" flags are discarded.

## ðŸŸ© Phase 3: ML Retraining & Tuning
**Reference:** GSoC Task T6
**The Problem:** Currently, the XGBoost F1 macro score sits around ~0.24, largely due to data confusion and zero hyperparameter tuning.
**The Fix:**
1. Run `python training/build_dataset.py` to generate the new feature block after Phase 1 is done.
2. Modify `training/train_model.py`:
   - Add Synthetic Minority Over-sampling Technique (**SMOTE**) to balance rare classes (like `gps_quality_poor`).
   - Implement **GridSearchCV** over XGBoost parameters (depth, learning rate, scale_pos_weight).
3. Switch from `OneVsRest` Multi-Label to strict Multi-Class classification (since our Root-Cause policy asserts there is ultimately only *one* structural root trigger per crash).

## ðŸŸ© Phase 4: The Final Gauntlet
**Reference:** GSoC Task T10 (Testing & Validation)
1. Run the benchmark pipeline on the newly trained ML model alone (`--engine ml`). Expected result: F1 > 0.60.
2. Run the pipeline on the Hybrid Engine (`--engine hybrid`). The combination of absolute rule constraints (FCR < 5%) plus tuned XGBoost bounds will yield Top-1 >= 85%.
3. Print final report and submit the PR.

---

### Immediate Next Step for Us:
Shall we jump directly into **Phase 1**? I can write a small script to parse the master pool's `ground_truth.json`, analyze the raw `.bin` parameters, and output a "Suggested Relabeling Manifest" for us to accept!
